\documentclass[a4paper]{article}
\usepackage{cmap}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

\parindent = 7mm
\oddsidemargin = 5mm
\topmargin = -10mm
\textheight = 240mm
\textwidth = 165mm
\linespread{1.5}

\begin{document}

\textbf{Слайд 2}
Цели данной работы заключаются в реализации нейронной сети, декодирующей код Хэмминга с вероятностью не менее 85\%. \\

\textbf{Слайд 3}
Для нейронной сети был выбран код Хэмминга(16, 11) с порождающей матрицей G, представленной на слайде.\\

\textbf{Слайд 4}
Нейронную сеть можно изобразить следующим образом. На входной слой поступает вектор входных сигналов. Далее, через скрытые слои нейронной сети они проходят до выходного слоя, образуя вектор выходных сигналов.\\

\textbf{Слайд 5}
Рассмотрим один нейрон. На вход он получает вектор сигналов с предыдущего слоя. Далее, вычисляется их скалярное произведение с вектором весов текущего слоя. Полученное значение поступает на вход некоторой функции активации, которая будет определена позже. И полученное значение отправляется к нейронам следующего слоя. \\

\textbf{Слайд 6}
Не трудно понять, что описанный процесс довольно ресурсоемкий. Поэтому необходим инструмент, позволяющий ускорить вычисления. Им был выбран Google Colaboratory. Это среда разработки, бесплатно предоставляющая видеокарту NVIDIA Tesla K80. 

Для работы необходимо создать файл.\\

\textbf{Слайд 7}
В появившемся окне во вкладке Runtime нужно выбрать GPU. \\

\textbf{Слайд 8}
Для обмена данными с Google Drive необходимо произвести аутентификацию Google с помощью команд, представленных на слайде. 

На этом настройка окончена и можно приступать к работе.\\

\textbf{Слайд 9}
1) Для обучения нейронной сети необходим набор данных. Сгенерируем все информационные слова выбранного кода.\\
2) Из них, путем умножения на матрицу G получим все кодовые слова.\\
3) Так как нейронная сеть должна будет исправлять ошибки в кодовых словах, сгенерируем для этого маски ошибок.\\

\textbf{Слайд 10}
1) С их помощью определим множество кодовых слов с ошибками. \\
2) Тогда набор данных D можно представить как объединение блоков B, состоящих из пар кодовых слов и кодовых слов с ошибками.\\

\textbf{Слайд 11}
Как было показано выше, нейронная сеть получает на вход вектор и выдает другой вектор. В нашей задаче нейронная сеть будет получать кодовое слово с ошибкой, а выдавать вектор, определяющий исправленное кодовое слово.\\

\textbf{Слайд 12}
1) Однако не каждая нейронная сеть способна выполнить поставленную задачу. Введем определение гиперпараметров. Это такие параметры нейронной сети, которые не изменяются в процессе обучения, но от выбора которых зависит последующее качество работы сети. \\
2) Для нашей сети ими будут: количество эпох обучения, количество слоев нейронной сети, количество нейронов в каждом слое.\\

\textbf{Слайд 13}
Также гиперпараметрами является функция потерь, которая характеризует величину отклонения ответа нейронной сети от правильного ответа.\\

\textbf{Слайд 14}
Упомянутая ранее функия активации тоже является гиперпараметром.\\

\textbf{Слайд 15}
Примеры таких функций представленны на слайде\\

\textbf{Слайд 16}
1) Множества значений перечисленных гиперпараметров образуют пространство гиперпараметров. Для поиска оптимального набора используем предназначенную для этого функцию fmin(). Для каждого набора она строит нейронную сеть, обучает ее, сохраняет историю обучения функцией History() и модели с наилучшим качеством функцией ModelCheckpoint().\\
2) Список сохраненных результатов был проанилизирован, в результате чего было обнаружено, что у моделей с малым количеством эпох обучения и количеством нейронов, линейными функциями активации качество обучения близко к нулю. Поэтому поиск был повторен в пространстве гиперпараметров, исключающих названные. В результате был обнаружен набор, при котором достигается наилучшее качество.\\

\textbf{Слайд 17}
Создание модели с этим набором выглядит так.\\

\textbf{Слайд 18}
Так как история обучения была сохранена, удобно ее визуализировать. На слайде представлен график изменения значений функции потерь в процессе обучения нейронной сети.\\

\textbf{Слайд 19}
Аналогично представлен график изменения точности модели.\\

\textbf{Слайд 20}
Для оценки качества определим вспомогательную функцию eq. И функцию А, которая возвращает долю правильных ответов нейронной сети. Проверка нейронной сети с выбранными параметрами показала, что в 92\% случаев, нейронная сеть исправляет ошибку правильно.


\end{document}